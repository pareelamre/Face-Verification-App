{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf953906",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "803adc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.9.1 in c:\\python\\python310\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-gpu==2.9.1 in c:\\python\\python310\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\python\\python310\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: matplotlib in c:\\python\\python310\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (0.26.0)\n",
      "Requirement already satisfied: packaging in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (21.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.0.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.22.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (14.0.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (4.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (58.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.46.3)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (3.7.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.12)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (3.19.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python\\python310\\lib\\site-packages (from tensorflow==2.9.1) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python\\python310\\lib\\site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python\\python310\\lib\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.27.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.12)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing dependencies\n",
    "!pip install tensorflow==2.9.1 tensorflow-gpu==2.9.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e9a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard dependencies\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ddb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow dependencies - Functional API\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107fed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid out of memory errors by setting GPU memory consumption growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimetnal.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923fe78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0263ceab",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make the directories\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOS_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(NEG_PATH)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(ANC_PATH)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'"
     ]
    }
   ],
   "source": [
    "# Make the directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bfd34",
   "metadata": {},
   "source": [
    "# COLLECT POSITIVES AND ANCHORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncompress Tar GZ Labelled  Faces in the Wild Dataset\n",
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29165f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move LFW Images to the following repository data/negative\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92182f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import uuid library to generate image names\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21061f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Cut down frame to 250x250\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "    \n",
    "    # Collect anchors\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        #Write out anchor name\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        #Write out positive name\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Realase the webcam        \n",
    "cap.release()\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10399d3",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e34fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    \n",
    "    data = []\n",
    "    for i in range(9):\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta = 0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100), np.random.randint(100))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "            \n",
    "        data.append(img)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5edf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(POS_PATH)):\n",
    "    img_path = os.path.join(POS_PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(ANC_PATH)):\n",
    "    img_path = os.path.join(ANC_PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241fbe95",
   "metadata": {},
   "source": [
    "# LOAD AND PREPROCESS IMAGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b367dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(3000)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(3000)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ecffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # read in image from file_path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # load in the image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (105,105))\n",
    "    # scale image to be between 0 and 1\n",
    "    img = img/255.0\n",
    "    \n",
    "    # return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a671f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labelled dataset\n",
    "# (anchor, positive) => 1,1,1,1,1\n",
    "# (anchor, negative) => 0,0,0,0,0\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "815a5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8f62f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data\\\\anchor\\\\d65994b2-e3d7-11ec-bcc7-f47b09d8627d.jpg',\n",
       " b'data\\\\positive\\\\54699bcd-e3d8-11ec-b122-f47b09d8627d.jpg',\n",
       " 1.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7bb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bba35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buid dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fab6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d3e2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a474a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f9649",
   "metadata": {},
   "source": [
    "# MODEL ENGINEERING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d680805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding layer\n",
    "def make_embedding():\n",
    "    inp = Input(shape=(105,105,3), name = 'input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding = 'same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding = 'same')(c2)\n",
    "    \n",
    "    # Third block\n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding = 'same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d9e14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b0a803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Distance Layer\n",
    "# Siamese L1 distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "    # Similarity calculation    \n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74dab749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Siamese model\n",
    "def make_siamese_model():\n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(105,105,3))\n",
    "    \n",
    "    # Validation image in the network\n",
    "    validation_image = Input(name='validation_img', shape=(105,105,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification Layer\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d3b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d847ed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['embedding[6][0]',              \n",
      "                                                                  'embedding[7][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b736fc",
   "metadata": {},
   "source": [
    "# TRAINING THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b40d71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loss and Optimizer\n",
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(1e-4) #0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abc3aa41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'siamese_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./training_checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m checkpoint_prefix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mckpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(opt\u001b[38;5;241m=\u001b[39mopt, siamese_model\u001b[38;5;241m=\u001b[39m\u001b[43msiamese_model\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'siamese_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Establish Checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e270cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = train_data.as_numpy_iterator()\n",
    "batch1 = test_batch.next()\n",
    "len(batch1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1cf078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Train step Function\n",
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15739f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "950a5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training loop\n",
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object\n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "    \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat)\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97340ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/10\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "37/38 [============================>.] - ETA: 20sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "38/38 [==============================] - 777s 21s/step\n",
      "\n",
      " Epoch 2/10\n",
      "38/38 [==============================] - 808s 21s/step\n",
      "\n",
      " Epoch 3/10\n",
      "38/38 [==============================] - 796s 21s/step\n",
      "\n",
      " Epoch 4/10\n",
      "38/38 [==============================] - 760s 20s/step\n",
      "\n",
      " Epoch 5/10\n",
      "38/38 [==============================] - 805s 21s/step\n",
      "\n",
      " Epoch 6/10\n",
      "38/38 [==============================] - 938s 25s/step\n",
      "\n",
      " Epoch 7/10\n",
      "31/38 [=======================>......] - ETA: 2:32"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data, EPOCHS)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Loop through each batch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Run train step here\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     progbar\u001b[38;5;241m.\u001b[39mupdate(idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Save checkpoints\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 10\n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bc435",
   "metadata": {},
   "source": [
    "# EVALUATE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e3e1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a447e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f4ca322",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'siamese_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict([test_input, test_val])\n\u001b[0;32m      3\u001b[0m y_hat\n",
      "\u001b[1;31mNameError\u001b[0m: name 'siamese_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b9c2798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post processing the results\n",
    "[1 if prediction > 0.5 else 0 for prediction in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcdef1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee0fdd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a metric object\n",
    "m = Recall()\n",
    "\n",
    "# Calculating the recall value\n",
    "m.update_state(y_true,y_hat)\n",
    "\n",
    "# Return recall result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "# Set plot size\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# Set first subplot\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[0])\n",
    "\n",
    "# Set second subplot\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eeb7d3",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc1b82ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save weights\n",
    "siamese_model.save('siamesemodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ed626a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Reload model\n",
    "model = tf.keras.models.load_model('siamesemodel.h5',\n",
    "                      custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy': tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1341afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9999893e-01],\n",
       "       [2.7214750e-07],\n",
       "       [9.9999988e-01],\n",
       "       [3.2909031e-07],\n",
       "       [9.9999952e-01],\n",
       "       [7.0533802e-04],\n",
       "       [9.9998623e-01],\n",
       "       [9.9998766e-01],\n",
       "       [5.8882641e-05],\n",
       "       [1.3588048e-07],\n",
       "       [9.9943262e-01],\n",
       "       [9.9591488e-01],\n",
       "       [9.9999899e-01],\n",
       "       [4.4132737e-04],\n",
       "       [9.9928033e-01],\n",
       "       [4.9260784e-08]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with reloaded model\n",
    "model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8668eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " l1_dist_2 (L1Dist)             (None, 4096)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            4097        ['l1_dist_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2b881",
   "metadata": {},
   "source": [
    "# REAL TIME TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c040689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification Function\n",
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    # Build results array\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "        input_img = preprocess(os.path.join('application_data', 'input_images', 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
    "    \n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "        \n",
    "    # Detection Threshold: Metric above which a prediction is considered positive\n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    \n",
    "    # Verification Threshold: Proportion of positive predictions/ total positive samples\n",
    "    verification = detection/len(os.listdir(os.path.join('application_data', 'verification_images')))\n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46842445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# OpenCV Real Time Verification\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "    \n",
    "    cv2.imshow('Verification', frame)\n",
    "    \n",
    "    # Verification trigger\n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        # Save input image to application_data/input_image folder\n",
    "        cv2.imwrite(os.path.join('application_data', 'input_images', 'input_image.jpg'), frame)\n",
    "        # Run verification\n",
    "        results, verified = verify(model, 0.5, 0.5)\n",
    "        print(verified)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec847c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.9999984]], dtype=float32),\n",
       " array([[0.99997216]], dtype=float32),\n",
       " array([[0.9999968]], dtype=float32),\n",
       " array([[0.99999887]], dtype=float32),\n",
       " array([[0.9999998]], dtype=float32),\n",
       " array([[0.9999997]], dtype=float32),\n",
       " array([[0.9999995]], dtype=float32),\n",
       " array([[0.9999956]], dtype=float32),\n",
       " array([[0.99990577]], dtype=float32),\n",
       " array([[0.99579865]], dtype=float32),\n",
       " array([[0.99579865]], dtype=float32),\n",
       " array([[0.894562]], dtype=float32),\n",
       " array([[0.76750934]], dtype=float32),\n",
       " array([[0.35325783]], dtype=float32),\n",
       " array([[0.9330828]], dtype=float32),\n",
       " array([[0.96608776]], dtype=float32),\n",
       " array([[0.02232494]], dtype=float32),\n",
       " array([[0.9999995]], dtype=float32),\n",
       " array([[0.99999994]], dtype=float32),\n",
       " array([[0.99897283]], dtype=float32),\n",
       " array([[0.96727353]], dtype=float32),\n",
       " array([[0.99996084]], dtype=float32),\n",
       " array([[0.99993646]], dtype=float32),\n",
       " array([[0.9999837]], dtype=float32),\n",
       " array([[0.9999247]], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1c391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
